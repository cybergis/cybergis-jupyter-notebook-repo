{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run ensemble SUMMA 3.0 model on HPC with CyberGISX Computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve a SUMMA model instance resource from HydroShare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For more info on this resource https://www.hydroshare.org/resource/13d6b84a9553410297a67fa366a56cb2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resource_id = '13d6b84a9553410297a67fa366a56cb2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from hs_restclient import HydroShare, HydroShareAuthBasic\n",
    "auth = HydroShareAuthBasic(\"cybergis\", \"demo\")\n",
    "hs = HydroShare(auth=auth)\n",
    "base_dir = \"/home/jovyan/work\"\n",
    "download_dir = os.path.join(base_dir, 'Downloads')\n",
    "!mkdir -p {download_dir}\n",
    "hs.getResource(resource_id, destination=download_dir, unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unzip model file\n",
    "model_folder_name = \"SummaModel_ReynoldsAspenStand_StomatalResistance\"\n",
    "content_folder = os.path.join(download_dir ,\"{}/{}/data/contents\".format(resource_id, resource_id))\n",
    "file_manager_rel_path = \"settings/summa_fileManager_riparianAspenSimpleResistance.txt\"\n",
    "import tempfile\n",
    "workspace_dir = os.path.join(base_dir, 'workspace')\n",
    "!mkdir -p {workspace_dir}\n",
    "unzip_dir = tempfile.mkdtemp(dir=workspace_dir)\n",
    "!cd {content_folder} && unzip -o {model_folder_name}.zip -d {unzip_dir}\n",
    "print(\"Unzipping Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_source_folder_path = os.path.join(unzip_dir, model_folder_name)\n",
    "!cd {model_source_folder_path} && chmod +x ./installTestCases_local.sh\n",
    "!cd {model_source_folder_path} && ./installTestCases_local.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use pySUMMA to build ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysumma as ps\n",
    "import os\n",
    "\n",
    "executable = \"/usr/bin/summa.exe\"\n",
    "! {executable} --version\n",
    "\n",
    "# path to the SUMMA filemanager file on Jupyter\n",
    "file_manager = os.path.join(model_source_folder_path, file_manager_rel_path)\n",
    "print(file_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pySUMMA Simulation Object\n",
    "S = ps.Simulation(executable, file_manager)\n",
    "\n",
    "# Configure the model\n",
    "S.manager['simStartTime'].value  = \"2006-07-01 00:00\"\n",
    "S.manager['simEndTime'].value = \"2007-09-30 00:00\"\n",
    "# Save configiuration to disk\n",
    "S.manager.write()\n",
    "print(S.decisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "# create ensemble\n",
    "# different parameterizations\n",
    "param_options = {\n",
    "    'rootDistExp': np.array([1.0, 0.5, 0.25])\n",
    "}\n",
    "\n",
    "# different parameterizations\n",
    "decision_options = {\n",
    "    \"stomResist\": [\"BallBerry\", \"Jarvis\", \"simpleResistance\"]\n",
    "}\n",
    "\n",
    "config = ps.ensemble.total_product(dec_conf=decision_options, param_trial_conf=param_options)\n",
    "\n",
    "with open(os.path.join(model_source_folder_path, 'summa_options.json'), 'w') as outfile:\n",
    "    json.dump(config, outfile)\n",
    "\n",
    "# check ensemble parameters    \n",
    "print(\"Number of ensemble runs: {}\".format(len(config)))\n",
    "print(json.dumps(config, indent=4, sort_keys=True)[:800])\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit model to HPC using New Job Submission Service Python Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from job_supervisor_client import *\n",
    "\n",
    "communitySummaSession = Session('summa', isJupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "communitySummaJob = communitySummaSession.job() # create new job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "communitySummaJob.upload(model_source_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "communitySummaJob.submit(payload={\n",
    "    \"node\": 9,\n",
    "    \"machine\": \"keeling\",\n",
    "    \"file_manager_rel_path\": file_manager_rel_path\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "communitySummaJob.events(liveOutput=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_dir = os.path.join(workspace_dir, \"{}\".format(communitySummaJob.id))\n",
    "!mkdir -p {job_dir}/output\n",
    "communitySummaJob.download(job_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check model output  -- NetCDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd {job_dir} && unzip *.zip -d output\n",
    "\n",
    "# check output directory\n",
    "output_path = os.path.join(job_dir, \"output\")\n",
    "# check SUMMA output file \n",
    "name_list = os.listdir(output_path)\n",
    "full_list = [os.path.join(output_path,i) for i in name_list if i.endswith(\".nc\")]\n",
    "sorted_list = sorted(full_list)\n",
    "\n",
    "for f in sorted_list:\n",
    "    print(f)\n",
    "print(\"Number of NC files: {}\".format(len(sorted_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot time series for total evapotranspiration (total ET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file_paths = [[s] for s in sorted_list]\n",
    "out_file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "# Create Method to Calculate Total ET for Each Hour of Day from SUMMA Output\n",
    "def calc_total_et(et_output_df):\n",
    "    total_et_data = (et_output_df['scalarLatHeatTotal'])*3600/2260000\n",
    "    # create dates(X-axis) attribute from ouput netcdf\n",
    "    dates = total_et_data.coords['time'].data\n",
    "    # create data value(Y-axis) attribute from ouput netcdf\n",
    "    data_values = total_et_data.data\n",
    "    # create two dimensional tabular data structure \n",
    "    total_et_df = pd.DataFrame(data_values, index=dates)\n",
    "    # round time to nearest hour (ex. 2006-10-01T00:59:59.99 -> 2006-10-01T01:00:00)\n",
    "    total_et_df.index = total_et_df.index.round(\"H\")\n",
    "    # set the time period to display plot \n",
    "    total_et_df = total_et_df.loc[\"2007-05-31 23:00:00\":\"2007-08-20 23:00:00\"]\n",
    "    # resample data by the average value hourly\n",
    "    total_et_df_hourly = total_et_df.resample(\"H\").mean()\n",
    "    # resample data by the average for hour of day\n",
    "    total_et_by_hour = total_et_df_hourly.groupby(total_et_df_hourly.index.hour).mean()\n",
    "    total_et_by_hour.index.name = 'hour'\n",
    "    total_et_by_hour.columns = ['ET']\n",
    "    # calculate 3 hour moving average\n",
    "    total_et_by_hour.loc['24'] = total_et_by_hour.loc[0].values\n",
    "    for index in range(1,23,1):\n",
    "        total_et_by_hour['ET'][index] = (total_et_by_hour['ET'][index-1]+total_et_by_hour['ET'][index]+total_et_by_hour['ET'][index+1])/3\n",
    "    return total_et_by_hour\n",
    "\n",
    "# Add Obervation Data from Aspen station in Reynolds Mountain East\n",
    "file_manager.split('/settings')[0]+'/testCases_data/validationData/ReynoldsCreek_eddyFlux.nc'\n",
    "# create pySUMMA Plotting Object\n",
    "Val_eddyFlux = xr.open_dataset(file_manager.split('/settings')[0]+'/data/validationData/ReynoldsCreek_eddyFlux.nc')\n",
    "# read Total Evapotranspiration(LE-wpl) AND Wind(WindFlag) from validation netcdf file\n",
    "Obs_Evapotranspitaton = Val_eddyFlux['LE-wpl']\n",
    "Obs_Wind = Val_eddyFlux['WindFlag']\n",
    "# create dates(X-axis) attribute from validation netcdf file\n",
    "dates = Obs_Evapotranspitaton.coords['time'].data\n",
    "# create obs_data(Y-axis) attribute from validation netcdf file\n",
    "obs_evap = Obs_Evapotranspitaton.data\n",
    "obs_wind = Obs_Wind.data\n",
    "# create two dimensional tabular data structure \n",
    "df_evap = pd.DataFrame(obs_evap, index=dates)\n",
    "df_wind = pd.DataFrame(obs_wind, index=dates)\n",
    "# set the time period to display plot\n",
    "df_evap_filt = df_evap.loc[\"2007-05-31 23:00:00\":\"2007-08-20 22:30:00\"]\n",
    "df_wind_filt = df_wind.loc[\"2007-05-31 23:00:00\":\"2007-08-20 22:30:00\"]   #\"2007-06-01\":\"2007-08-20\"\n",
    "# select aspen obervation station among three different stations\n",
    "df_evap_filt.columns = ['-','Obs_evap (aspen)','-']\n",
    "df_wind_filt.columns = ['-','Obs_wind (aspen)','-']\n",
    "# Combine total evapotranspiration and wind data\n",
    "obs_output = pd.concat([df_evap_filt['Obs_evap (aspen)'], df_wind_filt['Obs_wind (aspen)']], axis=1)\n",
    "# add hour column\n",
    "obs_output['hour'] = obs_output.index.hour\n",
    "# drop NaN and select row of wind = 0\n",
    "obs_output1 = obs_output.dropna()\n",
    "hourly_obs = obs_output1.loc[obs_output1['Obs_wind (aspen)'] == 0]\n",
    "# select obs data that has both 30min and 1hour data\n",
    "df = pd.DataFrame(hourly_obs['hour'].values, index=hourly_obs.index, columns=[\"hour1\"])\n",
    "count = 0\n",
    "for index, value in df.iterrows():\n",
    "    if df.loc[:, ['hour1']].iloc[count].values == df.loc[:, ['hour1']].iloc[count+1].values:\n",
    "        if count >= len(df)-3:\n",
    "            break\n",
    "        count = count + 2\n",
    "        pass\n",
    "    else:\n",
    "        df.iloc[count] = 100\n",
    "        count = count + 1        \n",
    "        \n",
    "# select and delete row of wind = 100\n",
    "delete_row = hourly_obs[hourly_obs.iloc[:,2]==100].index\n",
    "hourly_obs = hourly_obs.drop(delete_row)\n",
    "evap_hourly = hourly_obs.loc[:, ['Obs_evap (aspen)']]\n",
    "evap_hourly[\"Observations\"] = evap_hourly['Obs_evap (aspen)'].values\n",
    "# select evapotranspiration data at aspen station\n",
    "evap_hourly = hourly_obs.loc[:, ['Obs_evap (aspen)']]\n",
    "evap_hourly[\"Observations\"] = evap_hourly['Obs_evap (aspen)'].values\n",
    "# resample data by the average for hour of day\n",
    "df_gp_hr = evap_hourly.groupby([evap_hourly.index.hour, evap_hourly.index.minute]).mean()\n",
    "# Change unit from kgm-2s-1 to mm/hr \n",
    "df_gp_hr = df_gp_hr/2260000*3600\n",
    "# reset index so each row has an hour an minute column\n",
    "df_gp_hr.reset_index(inplace=True)\n",
    "# add hour and minute columns for plotting\n",
    "xvals = df_gp_hr.reset_index()['level_0'] + df_gp_hr.reset_index()['level_1']/60."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Plot\n",
    "BallBerry_rootDisExp_0_25 = xr.open_dataset(out_file_paths[0][0])\n",
    "BallBerry_rootDisExp_0_5 = xr.open_dataset(out_file_paths[1][0])\n",
    "BallBerry_rootDisExp_1_0 = xr.open_dataset(out_file_paths[2][0])\n",
    "BallBerry_rootDisExp_0_25_hour = calc_total_et(BallBerry_rootDisExp_0_25)\n",
    "BallBerry_rootDisExp_0_5_hour = calc_total_et(BallBerry_rootDisExp_0_5)\n",
    "BallBerry_rootDisExp_1_0_hour = calc_total_et(BallBerry_rootDisExp_1_0)\n",
    "# 2 Plot\n",
    "Jarvis_rootDisExp_0_25 = xr.open_dataset(out_file_paths[3][0])\n",
    "Jarvis_rootDisExp_0_5 = xr.open_dataset(out_file_paths[4][0])\n",
    "Jarvis_rootDisExp_1_0 = xr.open_dataset(out_file_paths[5][0])\n",
    "Jarvis_rootDisExp_0_25_hour = calc_total_et(Jarvis_rootDisExp_0_25)\n",
    "Jarvis_rootDisExp_0_5_hour = calc_total_et(Jarvis_rootDisExp_0_5)\n",
    "Jarvis_rootDisExp_1_0_hour = calc_total_et(Jarvis_rootDisExp_1_0)\n",
    "\n",
    "# 3 Plot\n",
    "simpleResistance_rootDisExp_0_25 = xr.open_dataset(out_file_paths[6][0])\n",
    "simpleResistance_rootDisExp_0_5 = xr.open_dataset(out_file_paths[7][0])\n",
    "simpleResistance_rootDisExp_1_0 = xr.open_dataset(out_file_paths[8][0])\n",
    "simpleResistance_rootDisExp_0_25_hour = calc_total_et(simpleResistance_rootDisExp_0_25)\n",
    "simpleResistance_rootDisExp_0_5_hour = calc_total_et(simpleResistance_rootDisExp_0_5)\n",
    "simpleResistance_rootDisExp_1_0_hour = calc_total_et(simpleResistance_rootDisExp_1_0)\n",
    "\n",
    "# 4 Plot\n",
    "rootDisExp_1_0_BallBerry = xr.open_dataset(out_file_paths[2][0])\n",
    "rootDisExp_1_0_Jarvis = xr.open_dataset(out_file_paths[5][0])\n",
    "rootDisExp_1_0_simpleResistance = xr.open_dataset(out_file_paths[8][0])\n",
    "rootDisExp_1_0_BallBerry_hour = calc_total_et(rootDisExp_1_0_BallBerry)\n",
    "rootDisExp_1_0_Jarvis_hour = calc_total_et(rootDisExp_1_0_Jarvis)\n",
    "rootDisExp_1_0_simpleResistance_hour = calc_total_et(rootDisExp_1_0_simpleResistance)\n",
    "\n",
    "# 5 Plot\n",
    "rootDisExp_0_5_BallBerry = xr.open_dataset(out_file_paths[1][0])\n",
    "rootDisExp_0_5_Jarvis = xr.open_dataset(out_file_paths[4][0])\n",
    "rootDisExp_0_5_simpleResistance = xr.open_dataset(out_file_paths[7][0])\n",
    "rootDisExp_0_5_BallBerry_hour = calc_total_et(rootDisExp_0_5_BallBerry)\n",
    "rootDisExp_0_5_Jarvis_hour = calc_total_et(rootDisExp_0_5_Jarvis)\n",
    "rootDisExp_0_5_simpleResistance_hour = calc_total_et(rootDisExp_0_5_simpleResistance)\n",
    "\n",
    "# 6 Plot\n",
    "rootDisExp_0_25_BallBerry = xr.open_dataset(out_file_paths[0][0])\n",
    "rootDisExp_0_25_Jarvis = xr.open_dataset(out_file_paths[3][0])\n",
    "rootDisExp_0_25_simpleResistance = xr.open_dataset(out_file_paths[6][0])\n",
    "rootDisExp_0_25_BallBerry_hour = calc_total_et(rootDisExp_0_25_BallBerry)\n",
    "rootDisExp_0_25_Jarvis_hour = calc_total_et(rootDisExp_0_25_Jarvis)\n",
    "rootDisExp_0_25_simpleResistance_hour = calc_total_et(rootDisExp_0_25_simpleResistance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,20))\n",
    "ax1 = fig.add_subplot(321)\n",
    "ax1.set_title(\"Reproducibility of Figure8 from Clark et al.(2015b)\", fontsize=12, color='red')\n",
    "ax1.plot(BallBerry_rootDisExp_1_0_hour.index, BallBerry_rootDisExp_1_0_hour['ET'], label='BallBerry (Root Exp = 1.0)', color='blue', linewidth=4.0)\n",
    "ax1.plot(BallBerry_rootDisExp_0_5_hour.index, BallBerry_rootDisExp_0_5_hour['ET'], label='BallBerry (Root Exp = 0.5)', color='green', linewidth=4.0)\n",
    "ax1.plot(BallBerry_rootDisExp_0_25_hour.index, BallBerry_rootDisExp_0_25_hour['ET'], label='BallBerry (Root Exp = 0.25)', color='orange', linewidth=4.0)\n",
    "\n",
    "ax2 = fig.add_subplot(322)\n",
    "ax2.plot(Jarvis_rootDisExp_1_0_hour.index, Jarvis_rootDisExp_1_0_hour['ET'], label='Jarvis (Root Exp = 1.0)', color='blue', linewidth=4.0)\n",
    "ax2.plot(Jarvis_rootDisExp_0_5_hour.index, Jarvis_rootDisExp_0_5_hour['ET'], label='Jarvis (Root Exp = 0.5)', color='green', linewidth=4.0)\n",
    "ax2.plot(Jarvis_rootDisExp_0_25_hour.index, Jarvis_rootDisExp_0_25_hour['ET'], label='Jarvis (Root Exp = 0.25)', color='orange', linewidth=4.0)\n",
    "\n",
    "ax3 = fig.add_subplot(323)\n",
    "ax3.plot(simpleResistance_rootDisExp_1_0_hour.index, simpleResistance_rootDisExp_1_0_hour['ET'], label='simpleResistance (Root Exp = 1.0)', color='blue', linewidth=4.0)\n",
    "ax3.plot(simpleResistance_rootDisExp_0_5_hour.index, simpleResistance_rootDisExp_0_5_hour['ET'], label='simpleResistance (Root Exp = 0.5)', color='green', linewidth=4.0)\n",
    "ax3.plot(simpleResistance_rootDisExp_0_25_hour.index, simpleResistance_rootDisExp_0_25_hour['ET'], label='simpleResistance (Root Exp = 0.25)', color='orange', linewidth=4.0)\n",
    "\n",
    "ax4 = fig.add_subplot(324)\n",
    "ax4.set_title(\"Reproducibility of Figure7 from Clark et al.(2015b)\", fontsize=12, color='red')\n",
    "ax4.plot(rootDisExp_1_0_BallBerry_hour.index, rootDisExp_1_0_BallBerry_hour['ET'], label='Root Exp = 1.0 (BallBerry)', color='blue', linewidth=4.0)\n",
    "ax4.plot(rootDisExp_1_0_Jarvis_hour.index, rootDisExp_1_0_Jarvis_hour['ET'], label='Root Exp = 1.0 (Jarvis)', color='green', linewidth=4.0)\n",
    "ax4.plot(rootDisExp_1_0_simpleResistance_hour.index, rootDisExp_1_0_simpleResistance_hour['ET'], label='Root Exp = 1.0 (simpleResistance)', color='orange', linewidth=4.0)\n",
    "\n",
    "ax5 = fig.add_subplot(325)\n",
    "ax5.plot(rootDisExp_0_5_BallBerry_hour.index, rootDisExp_0_5_BallBerry_hour['ET'], label='Root Exp = 0.5 (BallBerry)', color='blue', linewidth=4.0)\n",
    "ax5.plot(rootDisExp_0_5_Jarvis_hour.index, rootDisExp_0_5_Jarvis_hour['ET'], label='Root Exp = 0.5 (Jarvis)', color='green', linewidth=4.0)\n",
    "ax5.plot(rootDisExp_0_5_simpleResistance_hour.index, rootDisExp_0_5_simpleResistance_hour['ET'], label='Root Exp = 0.5 (simpleResistance)', color='orange', linewidth=4.0)\n",
    "\n",
    "ax6 = fig.add_subplot(326)\n",
    "ax6.plot(rootDisExp_0_25_BallBerry_hour.index, rootDisExp_0_25_BallBerry_hour['ET'], label='Root Exp = 0.25 (BallBerry)', color='blue', linewidth=4.0)\n",
    "ax6.plot(rootDisExp_0_25_Jarvis_hour.index, rootDisExp_0_25_Jarvis_hour['ET'], label='Root Exp = 0.25 (Jarvis)', color='green', linewidth=4.0)\n",
    "ax6.plot(rootDisExp_0_25_simpleResistance_hour.index, rootDisExp_0_25_simpleResistance_hour['ET'], label='Root Exp = 0.25 (simpleResistance)', color='orange', linewidth=4.0)\n",
    "\n",
    "axes = [ax1, ax2, ax3, ax4, ax5, ax6]\n",
    "for ax in axes:\n",
    "    # invert y axis\n",
    "    ax.invert_yaxis()\n",
    "    # plot scatter with x='xvals', y='Observation (aspen)'\n",
    "    ax.scatter(xvals, df_gp_hr['Observations'], color='black', s=100, label=\"Observations\")\n",
    "    # add x, y label\n",
    "    ax.set_xlabel('Time of day (hr)', fontsize=15)\n",
    "    ax.set_ylabel('Total evapotranspiration (mm/h)', fontsize=15)\n",
    "    # show up the legend\n",
    "    ax.legend(fontsize=11, loc=2)\n",
    "    ax.set_xlim([0,24])\n",
    "    ax.set_ylim([0,-0.6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Hydro-Python3",
   "language": "python",
   "name": "hydro-py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
